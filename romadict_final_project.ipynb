{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zve7jmPcNptv"
   },
   "source": [
    "# Финальный проект: цыганско-русский словарь #\n",
    "### Выполнили Кирилл Конча и Елизавета Клыкова (БКЛ181) ###\n",
    "### Часть 1: парсинг словаря, создание датафрейма ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EFUHiTSN_-XW"
   },
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A856dCecNpt1"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from collections import OrderedDict\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "pm = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самоучитель цыганского языка В.В. Шаповала в формате .pdf был распознан, а затем вычитан на предмет опечаток и ошибок распознавания и сохранен в файл 'romadict_txt.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g7pYVUIVLm0x"
   },
   "outputs": [],
   "source": [
    "# считывание файла построчно с удалением пустых строк\n",
    "lines = []\n",
    "with open('romadict_txt.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line != '\\n':\n",
    "            lines.append(line.strip('\\n'))\n",
    "\n",
    "# деление на две части (кривое, но самое простое решение)\n",
    "rom_lines = lines[0:2730]\n",
    "rus_lines = lines[2731:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарные статьи русской и цыганской статей имеют немного разную структуру (например, расположение тегов и т.д.). Функция parse_line принимает на вход одну строку словаря и язык, к которому относится слово, и с помощью регулярных выражений выделяет в ней несколько частей: слово, его перевод, словарные пометы (пока все вместе, деление позже), этимологию и специальную часть, указывающую, является ли слово формой какого-то другого слова. Любая из последних трех частей может отсутствовать.\n",
    "\n",
    "Функция возвращает список вида \\[слово, язык, перевод, теги, лемма с комментариями, этимология\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KRtbqx1fjI4Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42:15: E127 continuation line over-indented for visual indent\n"
     ]
    }
   ],
   "source": [
    "def parse_line(line, lang):\n",
    "    word_info = []\n",
    "    line = re.sub(';', ',', line)\n",
    "    if lang == 'rom':\n",
    "        # находим слово с тегами, разделяем\n",
    "        word_with_tags = re.search('(.+?) — ', line).group(1)\n",
    "        if ' (' in word_with_tags and '.' in word_with_tags:\n",
    "            word = re.search(r'(.+?) [(]', word_with_tags).group(1)\n",
    "            tags = re.search(r' [(](.+?)[)]', word_with_tags).group(1)\n",
    "        else:\n",
    "            word = word_with_tags\n",
    "            tags = ''\n",
    "        word = re.sub(' и ', ', ', word)\n",
    "\n",
    "        # получаем перевод и этимологию\n",
    "        definition = re.split(' — ', line)[-1]\n",
    "        if ' | ' in definition:\n",
    "            etymology = re.search(r'\\| (.+)', definition).group(1)\n",
    "            transl = definition.replace(etymology, '').strip(r' | ')\n",
    "        else:\n",
    "            etymology = ''\n",
    "            transl = definition\n",
    "\n",
    "        # получаем лемму, если есть, а затем отделяем перевод от\n",
    "        # указания на лемму\n",
    "        form_of = ''\n",
    "        if ' к ' in transl:\n",
    "            if '.' in transl and ',' not in transl:\n",
    "                form_of = re.search('([^,]*?к .+)', transl).group(1)\n",
    "            elif '.' in transl or ', ' in transl:\n",
    "                form_of = re.search(', ([^,]*?к .+)', transl).group(1)\n",
    "            transl = re.sub(re.escape(form_of), '', transl)\n",
    "            transl = re.sub(',$', '', transl.strip())\n",
    "\n",
    "        # часть тегов не удается получить на предыдущем этапе,\n",
    "        # т.к. они записаны у перевода, а не исходного слова\n",
    "        if transl.endswith(')'):\n",
    "            add_tags = re.search(r'([^\\(]+)?\\)$', transl).group(1)\n",
    "            bad_tags = ['букв.', 'т.е.', ')', 'ср.', 'Дж.', 'разг.', 'ж.',\n",
    "                        'мн.', 'м.', 'ед.']\n",
    "            if ('.' in add_tags or 'счетное слово' in add_tags) and \\\n",
    "              not any(t in add_tags for t in bad_tags):\n",
    "                if tags:\n",
    "                    tags = tags + ', ' + add_tags\n",
    "                else:\n",
    "                    tags = add_tags\n",
    "            transl = re.sub(re.escape(add_tags), '', transl)\n",
    "            transl = re.sub(',$', '', (re.sub(r' \\(\\)', '', transl)).strip())\n",
    "\n",
    "        if '.' in transl:\n",
    "            last = transl.split(',')[-1].strip()\n",
    "            more_tags = ['общая ф.', 'завис. ф.', 'прош.']\n",
    "            if last == 'зват. ф.' or any(t in last for t in more_tags):\n",
    "                if tags:\n",
    "                    tags = tags + ', ' + last\n",
    "                else:\n",
    "                    tags = last\n",
    "                transl = re.sub(re.escape(last), '', transl)\n",
    "                transl = re.sub(',$', '', transl.strip())\n",
    "\n",
    "    if lang == 'ru':\n",
    "        # в русской части теги обычно не у слова, а у перевода\n",
    "        word = re.search('(.+?) — ', line).group(1)\n",
    "        transl_with_tags = re.search(' — (.+)', line).group(1)\n",
    "        if ' (' in transl_with_tags and '.' in transl_with_tags:\n",
    "            transl = re.search(r'(.+?) [(]', transl_with_tags).group(1)\n",
    "            tags = re.search(r' [(](.+?)[)]', transl_with_tags).group(1)\n",
    "        else:\n",
    "            transl = transl_with_tags\n",
    "            tags = ''\n",
    "        transl = re.sub(' и ', ', ', transl)\n",
    "        # этимология у русских слов не указана\n",
    "        etymology = ''\n",
    "\n",
    "        # иногда теги все же бывают у слова\n",
    "        form_of = ''\n",
    "        if ' к ' in word:\n",
    "            if '.' in word and ',' not in word:\n",
    "                form_of = re.search('([^,]*?к .+)', word).group(1)\n",
    "            elif '.' in word:\n",
    "                form_of = re.search(', ([^,]*?к .+)', word).group(1)\n",
    "            word = re.sub(re.escape(form_of), '', word)\n",
    "            word = re.sub(',$', '', word.strip())\n",
    "\n",
    "        # отлавливаем пропущенные теги\n",
    "        if word.endswith(')') and '.' in word:\n",
    "            add_tags = re.search(r'\\(.+\\)$', word).group()\n",
    "            word = re.sub(re.escape(add_tags), '', word).strip()\n",
    "            add_tags = re.sub(r'[\\(\\)]', '', add_tags)\n",
    "            if tags:\n",
    "                tags = tags + ', ' + add_tags\n",
    "            else:\n",
    "                tags = add_tags\n",
    "\n",
    "    # добавляем всю полученную информацию в список\n",
    "    word_info.extend((word, lang, transl, tags, form_of, etymology))\n",
    "\n",
    "    return word_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция parse_all_lines парсит все строки на указанном языке, используя функцию parse_line. Полученная информация сохраняется в список x_words, где x - аббревиатура языка (rom или ru)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hL811Y98MVk8"
   },
   "outputs": [],
   "source": [
    "def parse_all_lines(lines, lang):\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        if len(re.findall(' — ', line)) == 1:\n",
    "            word_info = parse_line(line, lang)\n",
    "            words.append(word_info)\n",
    "        elif len(re.findall(' — ', line)) > 1:\n",
    "            parts = re.split('; ', line)\n",
    "            for part in parts:\n",
    "                word_info = parse_line(part, lang)\n",
    "                words.append(word_info)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RYWZmJsdg7nC"
   },
   "outputs": [],
   "source": [
    "# получаем информацию о словарных статьях\n",
    "rom_words = parse_all_lines(rom_lines, 'rom')\n",
    "rus_words = parse_all_lines(rus_lines, 'ru')\n",
    "\n",
    "# сохраняем в общий список\n",
    "all_words = rom_words + rus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uvVwVEuDNpt3"
   },
   "outputs": [],
   "source": [
    "# создаем датафрейм на основе полученного списка\n",
    "columns = ['word',  'lang', 'translation', 'tags', 'form_of', 'etymology']\n",
    "df = pd.DataFrame(all_words, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий этап - разделение тегов на категории (часть речи, число, род и т.д.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wpQuAGQqQJdk"
   },
   "outputs": [],
   "source": [
    "# нужные пометы сохраняем в списки\n",
    "pos_tags = ['сз.', 'част.', 'мест.', 'межд.', 'нар.', 'гл.', 'предл.',\n",
    "            'прич.', 'прил.', 'числ.', 'деепр.', 'сравн.']\n",
    "verb_tags = ['повел.', 'неп.', 'пер.', 'пер./неп.', 'прош.']\n",
    "case_tags = ['тв.', 'дат.', 'вин.', 'зват. ф.']\n",
    "gender_tags = ['м.', 'ж.', 'м./ж.']\n",
    "number_tags = ['ед.', 'мн.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b_iaaIH1BMeE"
   },
   "outputs": [],
   "source": [
    "# записываем теги (в т.ч. пустые) из столбца 'tags' в список\n",
    "word_tags = df['tags'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция split_tags принимает список значений колонки 'tags' и разделяет теги на 7 частей (не обязательно все они присутствуют в каждой статье, может не быть вообще ни одной): часть речи, глагольные теги (переходность и наклонение, но только повелительное), падеж, род, число и прочие пометы, объединенные в категорию other. Функция возвращает список словарей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iP9SFV3Q-dNk"
   },
   "outputs": [],
   "source": [
    "def split_tags(word_tags):\n",
    "    full_tag_info = []\n",
    "\n",
    "    for word in word_tags:\n",
    "        # создаем словарь с информацией о тегах слова\n",
    "        word_info = OrderedDict()\n",
    "        tag_types = ['pos', 'vform', 'case', 'gender',\n",
    "                     'number', 'other']\n",
    "        for ttype in tag_types:\n",
    "            word_info[ttype] = []\n",
    "\n",
    "        # здесь можно добавить проверку на (не)пустоту поля с тегами,\n",
    "        # но данных не очень много и скорость не страдает\n",
    "\n",
    "        # делим строку с тегами по запятым\n",
    "        word = re.sub(' и ', ', ', word)\n",
    "        tags = [t.strip() for t in word.split(',')]\n",
    "\n",
    "        # проверяем теги по одному\n",
    "        # функцией не получается, много специфичных моментов\n",
    "        for tag in tags:\n",
    "            if tag in pos_tags:\n",
    "                word_info['pos'].append(tag)\n",
    "            elif tag in case_tags:\n",
    "                word_info['case'].append(tag)\n",
    "            elif tag in verb_tags:\n",
    "                word_info['vform'].append(tag)\n",
    "                if tag == 'повел.' or tag == 'прош.':\n",
    "                    word_info['pos'].append('гл.')\n",
    "            elif tag in gender_tags:\n",
    "                word_info['gender'].append(tag)\n",
    "            elif tag in number_tags:\n",
    "                word_info['number'].append(tag)\n",
    "            elif 'гл.' in tag:\n",
    "                word_info['pos'].append('гл.')\n",
    "                vtags = re.sub('гл. ', '', tag).split('/')\n",
    "                for v in vtags:\n",
    "                    if v.strip() in verb_tags:\n",
    "                        word_info['vform'].append(v.strip())\n",
    "            elif 'предл.' in tag:\n",
    "                word_info['pos'].append('предл.')\n",
    "                word_info['other'].append(re.sub('предл. ', '', tag))\n",
    "            elif tag.startswith('ж.') or tag.startswith('м.'):\n",
    "                gender = tag.split()[0]\n",
    "                word_info['gender'].append(gender)\n",
    "            elif tag.endswith('ед.') or tag.endswith('мн.'):\n",
    "                num = tag.split()\n",
    "                if 'только' in tag:\n",
    "                    number = 'только ' + num[-1]\n",
    "                else:\n",
    "                    number = num[-1]\n",
    "                word_info['number'].append(number)\n",
    "            else:\n",
    "                word_info['other'].append(tag)\n",
    "\n",
    "        # перед записью в общий список объединяем\n",
    "        # значения словаря word_info через ', '\n",
    "        for key in word_info:\n",
    "            word_info[key] = ', '.join(word_info[key])\n",
    "        full_tag_info.append(word_info)\n",
    "\n",
    "    return full_tag_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "n3K1a5s5_xkT"
   },
   "outputs": [],
   "source": [
    "full_tag_info = split_tags(word_tags)\n",
    "\n",
    "# добавляем полученную информацию в датафрейм\n",
    "# исходная колонка со всеми тегами сохраняется\n",
    "tag_df = pd.DataFrame(full_tag_info)\n",
    "df = pd.concat([df, tag_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPOIVcSVgPOj"
   },
   "source": [
    "### Экспериментальная часть ###\n",
    "Мы попробовали добавить частеречные теги к словам, для которых они не указаны в исходном словаре. В качестве парсера был выбран pymorphy: он дает хорошую точность и работает быстрее, чем mystem (если говорить о модулях для юпитера), при этом парсить его выдачу гораздо проще, чем выдачу консольного mystem'a (который работает намного быстрее на больших текстовых файлах).\n",
    "\n",
    "Для цыганских слов выбирался тег русского перевода. Если вариантов перевода было несколько, учитывался первый, если pymorphy предалагал несколько разборов, выбирался наиболее вероятный. В случае, когда перевод слова состоял из нескольких слов (не считая пометы и примечания), устанавливалось pos = 'unknown'.\n",
    "\n",
    "**Важно:** никакие другие теги, кроме частеречных, мы не добавляли, так как даже в случае с частями речи возникало довольно много неточностей и/или случаев, когда приходилось ставить тег 'unknown'. Дальнейшая автоматическая разметка, на мой (Лиза К.) взгляд, нецелесообразна: надежнее доразметить вручную, тем более, что в получившемся датафрейме всего 4045 строк.\n",
    "\n",
    "Мы считали оригинальную разметку приоритетной (сохраняли ее там, где она была, и только приводили к универсальному виду - об этом см. ниже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jEpKnwO7yWjY"
   },
   "outputs": [],
   "source": [
    "words_with_pos = df[['word', 'lang', 'translation', 'pos']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Y1f4v0qxymUI"
   },
   "outputs": [],
   "source": [
    "parts_of_speech = []\n",
    "prons = ['я', 'ты', 'он', 'она']\n",
    "\n",
    "for word in words_with_pos:\n",
    "    # если часть речи уже есть в списке, ничего не парсим\n",
    "    if word[-1] != '':\n",
    "        pos = word[-1]\n",
    "    else:\n",
    "        pos = None\n",
    "        # дальше сложности, потому что русский перевод не всегда\n",
    "        # начинается с нужного слова, да и вообще не всегда есть\n",
    "        if word[1] == 'rom':\n",
    "            w = word[2]\n",
    "        elif word[1] == 'ru':\n",
    "            w = word[0]\n",
    "        if w.startswith('см.'):\n",
    "            pos = 'unknown'\n",
    "        else:\n",
    "            t = re.sub(r'\\(.+?\\)', '', re.sub(r'\\[.+?\\]', '', w)).strip()\n",
    "            if ',' in t:\n",
    "                t = t.split(',')[0].strip()\n",
    "            if ' ' not in t:\n",
    "                t = re.sub('!', '', t)\n",
    "                pos = pm.parse(t)[0].tag.POS\n",
    "            else:\n",
    "                parts = [p for p in t.split() if p not in prons]\n",
    "                # если после всех проверок перевод все еще содержит\n",
    "                # больше одного слова, то часть речи не определяется\n",
    "                # такие случаи нужно размечать вручную\n",
    "                if len(parts) == 1:\n",
    "                    pos = pm.parse(parts[0])[0].tag.POS\n",
    "                else:\n",
    "                    pos = 'unknown'\n",
    "    # сюда попадают случаи, с которыми не справился pymorphy\n",
    "    # их мало (2-3 случая)\n",
    "    if not pos:\n",
    "        pos = 'unknown'\n",
    "    parts_of_speech.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "_-jSFKuBRv0m",
    "outputId": "5ab3166a-deba-44d6-afb0-90d155a2a92f"
   },
   "outputs": [],
   "source": [
    "# записываем в датафрейм обновленные части речи\n",
    "df['pos'] = parts_of_speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXrw3JFphaRG"
   },
   "source": [
    "### Универсализация грамматических помет ###\n",
    "За основу был взят тегсет, принятый в Pymorphy (https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html), c определенными изменениями: число помет было уменьшено за счет объединения некоторых категорий (ADJF и ADJS - ADJ, PRTF и PRTS - PRTCP). Теги падежей, рода, числа, переходности/непереходности взяты из тегсета НКРЯ (https://ruscorpora.ru/new/corpora-morph.html) с небольшими изменениями - например, нет второго родительного и т.д.\n",
    "\n",
    "Здесь важно сказать, что в источнике очень ограниченный набор помет, относящихся к падежу существительных и времени глагола: они указаны лишь для небольшого числа слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LxYQxo4Il1Ts"
   },
   "outputs": [],
   "source": [
    "# правила унификации, для каждой категории свое\n",
    "universal_pos = {'сз.': 'CONJ', 'част.': 'PRCL', 'гл.': 'VERB',\n",
    "                 'мест.': 'PRON', 'межд.': 'INTJ', 'нар.': 'ADVB',\n",
    "                 'предл.': 'PREP', 'прич.': 'PRTCP', 'прил.': 'ADJ',\n",
    "                 'числ.': 'NUMR', 'деепр.': 'GRND', 'сущ.': 'NOUN',\n",
    "                 'сравн.': 'COMP', 'ADJS': 'ADJ', 'COMP': 'COMP',\n",
    "                 'ADJF': 'ADJ', 'ADVB': 'ADVB', 'CONJ': 'CONJ',\n",
    "                 'GRND': 'GRND', 'INFN': 'VERB', 'NOUN': 'NOUN',\n",
    "                 'NPRO': 'PRON', 'NUMR': 'NUMR', 'PRCL': 'PRCL',\n",
    "                 'PRED': 'ADVB', 'PREP': 'PREP', 'PRTF': 'PRTCP',\n",
    "                 'PRTS': 'PRTCP', 'VERB': 'VERB', 'INTJ': 'INTJ',\n",
    "                 'unknown': 'unknown'}\n",
    "universal_cases = {'им.': 'NOM', 'род.': 'GEN', 'дат.': 'DAT',\n",
    "                   'вин.': 'ACC', 'тв.': 'INS', 'местн.': 'LOC',\n",
    "                   'зват. ф.': 'VOC'}\n",
    "universal_vtags = {'пер.': 'TRAN', 'неп.': 'INTR',\n",
    "                   'повел.': 'IMPER', 'прош.': 'PAST'}\n",
    "universal_gender = {'м.': 'm', 'ж.': 'f', 'м./ж.': 'm.;f.'}\n",
    "universal_number = {'ед.': 'sg', 'мн.': 'pl', 'только мн.': 'pl'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция unify_tags принимает на вход список тегов из датафрейма и правило, согласно которому эти теги должны быть преобразованы, и возвращает видоизмененный список тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xLxvHS-YoNVl"
   },
   "outputs": [],
   "source": [
    "def unify_tags(tags, universal):\n",
    "    new_tags = []\n",
    "    for tag in tags:\n",
    "        value = []\n",
    "        if tag:\n",
    "            for v in [t.strip() for t in tag.split(',')]:\n",
    "                value.append(universal[v])\n",
    "            new_tag = ';'.join(value)\n",
    "        else:\n",
    "            new_tag = ''\n",
    "        new_tags.append(new_tag)\n",
    "    return new_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3HzAuYjzxXPy"
   },
   "outputs": [],
   "source": [
    "# наверное, можно упростить\n",
    "new_pos = unify_tags(df['pos'].values.tolist(), universal_pos)\n",
    "new_vtags = unify_tags(df['vform'].values.tolist(), universal_vtags)\n",
    "new_cases = unify_tags(df['case'].values.tolist(), universal_cases)\n",
    "new_gender = unify_tags(df['gender'].values.tolist(), universal_gender)\n",
    "new_number = unify_tags(df['number'].values.tolist(), universal_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MZB5ItRqpIum"
   },
   "outputs": [],
   "source": [
    "# кажется, можно красивее, но я умираю\n",
    "df['pos'] = new_pos\n",
    "df['vform'] = new_vtags\n",
    "df['case'] = new_cases\n",
    "df['gender'] = new_gender\n",
    "df['number'] = new_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "2TOvGLRVxaHJ",
    "outputId": "2da18b13-d901-451d-84ea-124a318aca7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lang</th>\n",
       "      <th>translation</th>\n",
       "      <th>tags</th>\n",
       "      <th>form_of</th>\n",
       "      <th>etymology</th>\n",
       "      <th>pos</th>\n",
       "      <th>vform</th>\n",
       "      <th>case</th>\n",
       "      <th>gender</th>\n",
       "      <th>number</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>а</td>\n",
       "      <td>rom</td>\n",
       "      <td>а</td>\n",
       "      <td>сз., част.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CONJ;PRCL</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ав</td>\n",
       "      <td>rom</td>\n",
       "      <td>приди, будь</td>\n",
       "      <td>повел.</td>\n",
       "      <td></td>\n",
       "      <td>снскр. ājā- приходить</td>\n",
       "      <td>VERB</td>\n",
       "      <td>IMPER</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>аваса, редко васа</td>\n",
       "      <td>rom</td>\n",
       "      <td>будем</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>авир, вавир</td>\n",
       "      <td>rom</td>\n",
       "      <td>другой, другая</td>\n",
       "      <td>мест.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PRON</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>аври</td>\n",
       "      <td>rom</td>\n",
       "      <td>вон</td>\n",
       "      <td>межд.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>INTJ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4040</td>\n",
       "      <td>язык</td>\n",
       "      <td>ru</td>\n",
       "      <td>чиб</td>\n",
       "      <td>ж.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>f</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4041</td>\n",
       "      <td>языкастый</td>\n",
       "      <td>ru</td>\n",
       "      <td>чибало</td>\n",
       "      <td>прил.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ADJ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4042</td>\n",
       "      <td>язычок</td>\n",
       "      <td>ru</td>\n",
       "      <td>чибори</td>\n",
       "      <td>ж.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>f</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4043</td>\n",
       "      <td>яичница</td>\n",
       "      <td>ru</td>\n",
       "      <td>дзэвэлы</td>\n",
       "      <td>ж.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>f</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4044</td>\n",
       "      <td>яйцо</td>\n",
       "      <td>ru</td>\n",
       "      <td>парноро, парнинько</td>\n",
       "      <td>м.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>m</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4045 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word lang         translation        tags form_of  \\\n",
       "0                     а  rom                   а  сз., част.           \n",
       "1                    ав  rom         приди, будь      повел.           \n",
       "2     аваса, редко васа  rom               будем                       \n",
       "3           авир, вавир  rom      другой, другая       мест.           \n",
       "4                  аври  rom                 вон       межд.           \n",
       "...                 ...  ...                 ...         ...     ...   \n",
       "4040               язык   ru                 чиб          ж.           \n",
       "4041          языкастый   ru              чибало       прил.           \n",
       "4042             язычок   ru              чибори          ж.           \n",
       "4043            яичница   ru             дзэвэлы          ж.           \n",
       "4044               яйцо   ru  парноро, парнинько          м.           \n",
       "\n",
       "                  etymology        pos  vform case gender number other  \n",
       "0                            CONJ;PRCL                                  \n",
       "1     снскр. ājā- приходить       VERB  IMPER                           \n",
       "2                                 VERB                                  \n",
       "3                                 PRON                                  \n",
       "4                                 INTJ                                  \n",
       "...                     ...        ...    ...  ...    ...    ...   ...  \n",
       "4040                              NOUN                  f               \n",
       "4041                               ADJ                                  \n",
       "4042                              NOUN                  f               \n",
       "4043                              NOUN                  f               \n",
       "4044                              NOUN                  m               \n",
       "\n",
       "[4045 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнения после защит ###\n",
    "Борис Леонидович посоветовал выделить из статей типа \"аваса, редко васа\" помету \"редко\" и убрать ее из поля word, что и было сделано с помощью кода ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0, len(df)):\n",
    "    if 'редк.' in df['word'][j] or 'редко' in df['word'][j]:\n",
    "        switch = 0\n",
    "        string = ''\n",
    "        other = ''\n",
    "        for i in df['word'][j].split(' '):\n",
    "            if i != 'редк.' and i != 'редко' and switch == 0:\n",
    "                new = i.strip(',')\n",
    "                if len(string) == 0:\n",
    "                    string = string + new\n",
    "                else:\n",
    "                    string = string + ', ' + new\n",
    "            if i == 'редк.' or i == 'редко':\n",
    "                switch = 1\n",
    "                other = other + 'редко'\n",
    "            if switch == 1 and i != 'редк.' and i != 'редко':\n",
    "                other = other + ' ' + i\n",
    "        df['word'][j] = string\n",
    "        if len(df['other'][j]) == 0:\n",
    "            df['other'][j] = other\n",
    "        else:\n",
    "            df['other'][j] = df['other'][j] + '; ' + other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем готовый датафрейм в формате .tsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gkrktcIeAaG-"
   },
   "outputs": [],
   "source": [
    "df.to_csv('romadict_dataframe.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPJrG-2WAlPe"
   },
   "source": [
    "### Часть 2: создание json-файла для веб-версии ###\n",
    "Веб-версия словаря доступна по ссылке https://romadict.linghub.ru.\n",
    "\n",
    "Возьмем из датафрейма все колонки и сделаем из них список словарей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1Smxdp3MMbao"
   },
   "outputs": [],
   "source": [
    "list_d = []\n",
    "for i in range(0, len(df)):\n",
    "    dic = {}\n",
    "    dic['id'] = i\n",
    "    dic['word'] = df['word'][i]\n",
    "    dic['lang'] = df['lang'][i]\n",
    "    dic['translation'] = df['translation'][i]\n",
    "    dic['_tags'] = df['tags'][i]\n",
    "    dic['etymology'] = df['etymology'][i]\n",
    "    dic['pos'] = df['pos'][i]\n",
    "    dic['_form_of'] = df['form_of'][i]\n",
    "    dic['_vform'] = df['vform'][i]\n",
    "    dic['_case'] = df['case'][i]\n",
    "    dic['_gender'] = df['gender'][i]\n",
    "    dic['_number'] = df['number'][i]\n",
    "    dic['_other'] = df['other'][i]\n",
    "    list_d.append(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем данные к нужному для фреймворка виду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9Cbl2I5oM9VU"
   },
   "outputs": [],
   "source": [
    "data = {'data': list_d}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним в json-файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_3XRRZxiNA1o"
   },
   "outputs": [],
   "source": [
    "with open('data.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(data, fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIb0-tVnSQYp"
   },
   "source": [
    "### Часть 3: создание xml-файла в TEI ###\n",
    "Считываем датафрейм (считывание дает возможность не перезапускать весь код, который был выше):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "a6CMX0BsA-pQ"
   },
   "outputs": [],
   "source": [
    "df_file = pd.read_csv('romadict_dataframe.tsv', sep='\\t')\n",
    "df_file.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "zh35iu9VXieA"
   },
   "outputs": [],
   "source": [
    "# делим на цыганскую и русскую части\n",
    "rom_rows = df_file[df_file['lang'] == 'rom'].values.tolist()\n",
    "rus_rows = df_file[df_file['lang'] == 'ru'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbYElukrBGy-"
   },
   "source": [
    "Для создания XML-файла используется модуль lxml. Сначала оформляем шапку (doctype добавим в самом конце, это проще сделать вручную)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = etree.Element('TEI', xmlns='http://www.tei-c.org/ns/1.0')\n",
    "root.set('{http://www.w3.org/XML/1998/namespace}lang', 'ru')\n",
    "header = etree.SubElement(root, 'teiHeader')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая часть - fileDesc; она содержит заголовок, информацию об авторах, данные словаря (кол-во статей, место и дату публикации) и источник, откуда взяты данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_desc = etree.SubElement(header, 'fileDesc')\n",
    "\n",
    "title_stmt = etree.SubElement(file_desc, 'titleStmt')\n",
    "title = etree.SubElement(title_stmt, 'title')\n",
    "title.text = 'Цыганско-русский и русско-цыганский словарь'\n",
    "\n",
    "resp_stmt = etree.SubElement(title_stmt, 'respStmt')\n",
    "resp1 = etree.SubElement(resp_stmt, 'resp')\n",
    "resp1.text = 'Авторы:'\n",
    "name1 = etree.SubElement(resp_stmt, 'name')\n",
    "name1.text = 'Елизавета Клыкова '\n",
    "email1 = etree.SubElement(name1, 'email',\n",
    "                          value='eaklykova@edu.hse.ru')\n",
    "email1.text = 'eaklykova@edu.hse.ru,'\n",
    "\n",
    "resp2 = etree.SubElement(resp_stmt, 'resp')\n",
    "name2 = etree.SubElement(resp_stmt, 'name')\n",
    "name2.text = 'Кирилл Конча '\n",
    "email2 = etree.SubElement(name2, 'email',\n",
    "                          value='majortomblog@gmail.com')\n",
    "email2.text = 'majortomblog@gmail.com'\n",
    "\n",
    "length = etree.SubElement(file_desc, 'extent')\n",
    "length.text = '4045 статей'\n",
    "\n",
    "pub_stmt = etree.SubElement(file_desc, 'publicationStmt')\n",
    "pub_place = etree.SubElement(pub_stmt, 'pubPlace')\n",
    "ref = etree.SubElement(\n",
    "    pub_place, 'ref', target='https://github.com/eaklykova/romadict')\n",
    "ref.text = 'https://github.com/eaklykova/romadict'\n",
    "date = etree.SubElement(pub_stmt, 'date', when='2021')\n",
    "date.text = 'март 2021 г.'\n",
    "\n",
    "source_desc = etree.SubElement(file_desc, 'sourceDesc')\n",
    "source = etree.SubElement(source_desc, 'bibl')\n",
    "source.text = '''Шаповал, В.В. Самоучитель цыганского языка \\\n",
    "(русска рома: севернорусский диалект). Учебное пособие. \\\n",
    "М.: АСТ, 2007.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая часть - encodingDesc, где хранится описание проекта и ссылки на курс и руководителей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_desc = etree.SubElement(header, 'encodingDesc')\n",
    "project_desc = etree.SubElement(encoding_desc, 'projectDesc')\n",
    "par1 = etree.SubElement(project_desc, 'p')\n",
    "par1.text = '''Проект выполнен в рамках дисциплины «Теоретическая \\\n",
    "и прикладная лексикография», которая преподается в Школе лингвистики \\\n",
    "НИУ ВШЭ (Факультет гуманитарных наук). '''\n",
    "course_link = etree.SubElement(\n",
    "    par1, 'ref',\n",
    "    target='https://www.hse.ru/ba/ling/courses/375293130.html')\n",
    "course_link.text = '''Cсылка на курс: \\\n",
    "https://www.hse.ru/ba/ling/courses/375293130.html.'''\n",
    "\n",
    "par2 = etree.SubElement(project_desc, 'p')\n",
    "par2.text = 'Преподаватели дисциплины:'\n",
    "prof_list = etree.SubElement(par2, 'list', rend='bulleted')\n",
    "\n",
    "prof1 = etree.SubElement(prof_list, 'item')\n",
    "prof1_link = etree.SubElement(\n",
    "    prof1, 'ref', target='https://www.hse.ru/staff/olesar')\n",
    "prof1_link.text = 'О.Н. Ляшевская (руководитель проекта)'\n",
    "\n",
    "prof2 = etree.SubElement(prof_list, 'item')\n",
    "prof2_link = etree.SubElement(\n",
    "    prof2, 'ref', target='https://www.hse.ru/org/persons/34792977')\n",
    "prof2_link.text = 'В.Ю. Апресян'\n",
    "\n",
    "prof3 = etree.SubElement(prof_list, 'item')\n",
    "prof3_link = etree.SubElement(\n",
    "    prof3, 'ref', target='https://www.hse.ru/org/persons/34616715')\n",
    "prof3_link.text = 'Б.Л. Иомдин'\n",
    "\n",
    "# не нашла ссылку :(\n",
    "prof4 = etree.SubElement(prof_list, 'item')\n",
    "prof4_link = etree.SubElement(prof4, 'ref')\n",
    "prof4_link.text = 'Е.В. Еникеева'\n",
    "\n",
    "par3 = etree.SubElement(project_desc, 'p')\n",
    "par3.text = '''В рамках проекта отрывок из Самоучителя \\\n",
    "цыганского языка был оцифрован и преобразован в электронный \\\n",
    "словарь. Онлайн-версия словаря размещена по ссылке '''\n",
    "dict_link = etree.SubElement(\n",
    "    par3, 'ref', target='https://romadict.linghub.ru')\n",
    "dict_link.text = 'https://romadict.linghub.ru.'\n",
    "\n",
    "par4 = etree.SubElement(project_desc, 'p')\n",
    "par4.text = 'Репозиторий проекта на Github: '\n",
    "github_link = etree.SubElement(\n",
    "    par4, 'ref', target='https://github.com/eaklykova/romadict')\n",
    "github_link.text = 'https://github.com/eaklykova/romadict.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, содержательная часть со словарными статьями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = etree.SubElement(root, 'text')\n",
    "text.set('{http://www.w3.org/XML/1998/namespace}lang', 'ru')\n",
    "body = etree.SubElement(text, 'body')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция make_tei принимает список строк датафрейма, относящихся к одному языку, и создает элемент \\<entry\\> с вложенными тегами. Большая часть тегов не добавляется, если в датафрейме нет значения, которое должно в них располагаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "OxTIxJZpBKFY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87:15: E127 continuation line over-indented for visual indent\n"
     ]
    }
   ],
   "source": [
    "def make_tei(rows):\n",
    "    for row in rows:\n",
    "        # в кач-ве id берем только первое слово без запятых и пробелов\n",
    "        # добавляем язык, чтобы минимизировать вероятность совпадений\n",
    "        word_parts = row[0].split(',')[0].strip()\n",
    "        word_id = word_parts.split()[0] + '_' + row[1]\n",
    "\n",
    "        # одно entry - одно слово/лексема\n",
    "        entry = etree.SubElement(body, 'entry', type='mainEntry')\n",
    "        entry.set('{http://www.w3.org/XML/1998/namespace}lang', row[1])\n",
    "        entry.set('{http://www.w3.org/XML/1998/namespace}id', word_id)\n",
    "\n",
    "        # само слово\n",
    "        form = etree.SubElement(entry, 'form', type='word')\n",
    "        orth = etree.SubElement(form, 'orth')\n",
    "        orth.text = row[0]\n",
    "\n",
    "        # gramGrp содержит все грамматические пометы\n",
    "        gram_grp = etree.SubElement(entry, 'gramGrp')\n",
    "\n",
    "        # часть речи\n",
    "        pos = etree.SubElement(gram_grp, 'pos', type='pos', value=row[6])\n",
    "        pos.text = row[6]\n",
    "\n",
    "        # глагольные теги\n",
    "        if row[7]:\n",
    "            vt = etree.SubElement(\n",
    "                gram_grp, 'v_info', type='v_info', value=row[7])\n",
    "            vt.text = row[7]\n",
    "\n",
    "        # падеж\n",
    "        if row[8]:\n",
    "            gender = etree.SubElement(\n",
    "                gram_grp, 'case', type='case', value=row[8])\n",
    "            gender.text = row[8]\n",
    "\n",
    "        # род\n",
    "        if row[9]:\n",
    "            gender = etree.SubElement(\n",
    "                gram_grp, 'gen', type='gen', value=row[9])\n",
    "            gender.text = row[9]\n",
    "\n",
    "        # число\n",
    "        if row[10]:\n",
    "            number = etree.SubElement(\n",
    "                gram_grp, 'num', type='num', value=row[10])\n",
    "            number.text = row[10]\n",
    "\n",
    "        # другие пометы (столбец 'other')\n",
    "        if row[11]:\n",
    "            other = etree.SubElement(entry, 'notes')\n",
    "            other.text = row[11]\n",
    "\n",
    "        # если слово является формой лексемы и это указано в словаре,\n",
    "        # добавляем специальное поле и ссылку на лексему\n",
    "        if row[4]:\n",
    "            hyper_entry = etree.SubElement(entry, 'xr', type='cf')\n",
    "            # составляем id: с помощью регулярных выражений\n",
    "            # находим нужную часть строки\n",
    "            if ')' not in row[4]:\n",
    "                hyper_id = row[4].split()[-1]\n",
    "            else:\n",
    "                hyp = re.search(r'(.+)\\(', row[4]).group(1)\n",
    "                hyper_id = hyp.strip().split()[-1]\n",
    "\n",
    "            # добавляем язык, как и в случае с word_id\n",
    "            # поле form_of всегда ведет к цыганской статье\n",
    "            link_to_hyper = '#' + hyper_id + '_rom'\n",
    "            form_of = etree.SubElement(hyper_entry, 'ref',\n",
    "                                       target=link_to_hyper)\n",
    "            form_of.text = row[4]\n",
    "\n",
    "        # хочется, чтобы перевод позволял перейти на аналогичную статью\n",
    "        # другого языка, поэтому нужна ссылка; это сложно, потому что\n",
    "        # перевод плохо парсится и нет гарантии, что это слово есть\n",
    "        # среди статей другого языка -> нужна ручная доработка\n",
    "        senses = etree.SubElement(entry, 'sense')\n",
    "        cit = etree.SubElement(senses, 'cit', type='trans')\n",
    "        translation = etree.SubElement(cit, 'quote', value=row[2])\n",
    "        if row[2]:\n",
    "            # удаляем ненужные элементы\n",
    "            tr_link = re.sub(r'\\[.+?\\]', '', row[2])\n",
    "            tr_link = re.sub('см. ', '', tr_link.split(',')[0].strip())\n",
    "            tr_parts = tr_link.split()\n",
    "            # выбираем нужную часть и подставляем в id\n",
    "            if len(tr_parts) == 2 and \\\n",
    "              pm.parse(tr_parts[0])[0].tag.POS == 'PREP':\n",
    "                key = tr_parts[1]\n",
    "            else:\n",
    "                key = tr_parts[0]\n",
    "            link_to_transl = '#' + key\n",
    "            # добавляем аббревиатуру языка, для рус. слов 'rom' и наоборот\n",
    "            if row[1] == 'rom':\n",
    "                link_to_transl += '_ru'\n",
    "            else:\n",
    "                link_to_transl += '_rom'\n",
    "            transl = etree.SubElement(\n",
    "                translation, 'ref', target=link_to_transl)\n",
    "            transl.text = row[2]\n",
    "        else:\n",
    "            # в очень редких случаях перевода нет (только теги)\n",
    "            translation.text = '—'\n",
    "\n",
    "        # этимология\n",
    "        if row[5]:\n",
    "            etymology = etree.SubElement(entry, 'etym', type='etym')\n",
    "            etymology.text = row[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем файл по частям, добавляя между частями соответствующие заголовки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "XVnZEgr4BXRs"
   },
   "outputs": [],
   "source": [
    "rom_title = etree.SubElement(body, 'div', type='title')\n",
    "rom_text = etree.SubElement(rom_title, 'p')\n",
    "rom_text.text = 'ЦЫГАНСКО-РУССКИЙ СЛОВАРЬ'\n",
    "make_tei(rom_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "iLDZuGcRBY2k"
   },
   "outputs": [],
   "source": [
    "rus_title = etree.SubElement(body, 'div', type='title')\n",
    "rus_text = etree.SubElement(rus_title, 'p')\n",
    "rus_text.text = 'РУССКО-ЦЫГАНСКИЙ СЛОВАРЬ'\n",
    "make_tei(rus_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzCDL-BWBcgE"
   },
   "source": [
    "Записываем готовый xml-документ в файл \"romadict_xml.xml\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "yCcqOj9YBaQ8"
   },
   "outputs": [],
   "source": [
    "tree = root.getroottree()\n",
    "tree.write('romadict_xml.xml', encoding='utf-8', pretty_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1tep8k3Bght"
   },
   "source": [
    "Добавим в готовый xml-файл переводы строки между леммами для удобства восприятия (способ неизящный, но через lxml это делать сложно - если нужно изменить один конкретный отступ, то нужно прописывать и все остальные)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "NvBqKDZlBeyq"
   },
   "outputs": [],
   "source": [
    "with open('romadict_xml.xml', 'r+', encoding='utf-8') as f:\n",
    "    xml_file = f.read()\n",
    "    xml_with_blanks = re.sub('<entry', '\\n\\n    <entry', xml_file)\n",
    "    doctype = '''<?xml version='1.0' encoding='UTF-8'?>\n",
    "<?xml-stylesheet type='text/css' href='romadict.css'?>\n",
    "<!DOCTYPE TEI SYSTEM 'freedict-P5.dtd'>\\n\\n'''\n",
    "    xml_with_doctype = doctype + xml_with_blanks\n",
    "    f.seek(0)\n",
    "    f.write(xml_with_doctype)\n",
    "    f.truncate()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "romadict_final_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
